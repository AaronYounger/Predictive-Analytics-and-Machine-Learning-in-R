---
title: "DAT-4253 LM 9 - Lab 2: Regression with Transformations"
author: "Aaron Younger"
format:
  html: 
    code-fold: false
    code-overflow: wrap
execute:
  warning: false
  messages: false
  echo: true
  include: true
toc: false
toc-location: left
number-sections: false
editor: source
---

# Business Understanding
The client, Jack Person, the Executive Director of a health public policy organization, has extended his health research into the area of assessing personal well-being. This Analysis will be focused on finding the relationship that age and income have on happiness.\

# Data Understanding

## R Version

```{r}
suppressWarnings(RNGversion("3.5.3"))
options(scipen=999)

```
## Libraries

```{r}
library(readxl)
library(DataExplorer)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(e1071)
library(dlookr)
library(caret)
library(moments)
library(auditor)
library(Metrics)

```
## Import Dataset

```{r}
happy_data <- read_excel("jaggia_ba_2e_ch08_data.xlsx", 
    sheet = "Happiness")
View(happy_data)

```

## Dataset Exploration

```{r}
happy_data %>% head()
happy_data %>% tail()
happy_data %>% nrow()
happy_data %>% ncol()
happy_data %>% plot_intro()
happy_data %>% plot_missing()
happy_data %>% str()

```
Comments on Data Exploration:\
This dataset has 100 rows and three columns. All columns are continuous/numeric columns, the columns are Happiness, Age, and Income. This dataset has no missing values.\

Variable Key:\
- Age: Represents the Age of the individual.\
- Happiness: Overall happiness score, higher values represent greater happiness. The Dependent Variable.\
- Income: Annual personal income.\


## EDA

### Distribution of Numeric Values

```{r}
happy_data %>% plot_density()

```
Comments on distribution of numeric values:\
Based of the density plots, Happiness and Income seem to be normally distributed. Age seems to also be relatively normally distributed but bimodal with a two clusters of ages.\

### Skewness of Numeric Variables

```{r}
apply(happy_data[,1:3], 2, skewness)


```
Comments on Skewness:\
These variables are left skewed but no extreme enough to base non-normality off skewness.\


```{r}
apply(happy_data[,1:3], 2, kurtosis)

```
Comments on Kurtosis:\
All three variables have kurtosis values close to 3 or slightly below, which indicates the variables have no major deviation from normality.\


### Look For Outliers

```{r}
diagnose_outlier(happy_data)

```
Comments on Outliers:\
This dataset has no outliers.\

### Q-Q Plots

```{r}
DataExplorer::plot_qq(happy_data)

```

### Graphing Numeric Variables

#### Scatterplot of Happiness by Age

```{r}
ggplot(happy_data, aes(x = Age, y = Happiness)) +
  geom_point(color = "blue") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  labs(
    title = "Relationship between Happiness and Age",
    x = "Age",
    y = "Happiness"
  ) +
  theme_minimal()


```
Comments on Relationship between Happiness and Age:\
Age and Happiness have a quadratic relationship, happiness is higher in the 30's then happiness goes down until about age 55 then it happiness goes back up.\

#### Scatterplot of Happiness by Income

```{r}
ggplot(happy_data, aes(x = Income, y = Happiness)) +
  geom_point(color = "blue") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  labs(
    title = "Relationship between Happiness and Income",
    x = "Income",
    y = "Happiness"
  ) +
  theme_minimal()


```

#### Transform Income to Log

```{r}
happy_data <- happy_data %>% 
  mutate(log_income = log(Income))
View(happy_data)

```

#### Scatterplot of Happiness by log Income

```{r}
ggplot(happy_data, aes(x = log_income, y = Happiness)) +
  geom_point() +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  labs(
    title = "Relationship between Happiness and Log Income",
    x = "Income",
    y = "Happiness"
  ) +
  theme_minimal()


```
Comments on relationship between Happiness and Income/log Income:\
Happiness and Income have a positive relationship where as income goes up so does happiness, however this relationship is not perfectly linear. The relationship between happiness and log income is also positive, as log income goes up so does happiness, however this relationship is a lot more linear.\

### Correlation Matrix

```{r}
DataExplorer::plot_correlation(happy_data)


```
Comments on Correlation Matrix:\
All predictor variables are positively correlated with happiness, income is strongly correlated with happiness and age is moderately correlated with happiness. Happiness is also slightly more correlated to log_income then non-log income.\

# Data Preperation

```{r}
happy_data <- happy_data %>% 
  mutate(quad_age = Age^2)


set.seed(1)
my_index <- createDataPartition(happy_data$Happiness, p = 0.8, list = FALSE)
trainset <- happy_data[my_index, ]
testset <- happy_data[-my_index, ]

## Mean is very close
mean(trainset$Happiness)
mean(testset$Happiness)


```
Comments on Data Partition:\
Before modeling the dataset is partitioned into a 80/20 split so the data can be trained then tested. A set.seed of 1 was also given for reproducibility of the model results. The mean of the dependent variable across train and test set was very close.\

# Modeling - Assume a 10% Level of Signifcance

## Baseline Model

```{r}
lm_ctrl <- trainControl(method = "cv", number = 10)

set.seed(1)
model1 <- train(Happiness ~ Age + Income, data = trainset, method = "lm", trControl = lm_ctrl)
summary(model1)


```
Coefficient Significance:\
- Age: Significant predictor of Happiness. For every one-year increase in age, on average Happiness increases on average by 0.2198 units, ceteris paribus.\
- Income: Highly significant predictor of Happiness. For every one-unit increase in Income, on average Happiness increases on average by 0.000143 units, ceteris paribus.




## Model with Quadratic Age and Log income 

```{r}

set.seed(1)
model2 <- train(Happiness ~ Age + quad_age + log_income, data = trainset, method = "lm", trControl = lm_ctrl)
summary(model2)

```
Coefficient Significance:\
- Age: Age is a significant predictor of happiness and negative, indicating that as age increases, happiness initially decreases when holding other variables constant.\
- quad_age: Quadratic of age is a Significant predictor of happiness and positive, showing a quadratic relationship between Age and Happiness. This means originally happiness decreases as age increases but after a certain age happiness starts increasing again.\
- log_income: Log Income is a significant predictor of happiness and positive, coefficient explanation in parial effects for Income.


## Partial effects for Income:
What this is referring to is since income positively affects happiness but its in log form, each increase in income yields a smaller gain to happiness, a diminishing return. So for the model 2 coefficient of log income a 1% increase in income leads to a 0.13+ point increase in happiness, and a 10% increase in income leads to a 1.31% point increase in happiness, ceteris paribus.\


## Optima for Age

```{r}
b1 <- coef(model2$finalModel)["Age"]
b2 <- coef(model2$finalModel)["quad_age"]

optimum_age <- -b1 / (2 * b2)
optimum_age

```
Comments on the Optima Age:\
The Optima Age is 50.5 which means after 50.5 age starts trending upwards again in relation to age.\

# Evaluation

## Predict Models
```{r}
pred_m1 <- predict(model1, newdata = testset)
pred_m2 <- predict(model2, newdata = testset)

testset_results <- cbind(
  testset,
  pred_m1,
  pred_m2
)
View(testset_results)

```

## Numeric Evaluation Metrics

```{r}
RMSE_m1 <- rmse(testset$Happiness, pred_m1)
RMSE_m2 <- rmse(testset$Happiness, pred_m2)

## MAE Metrics
MAE_m1 <- mae(testset$Happiness, pred_m1)
MAE_m2 <- mae(testset$Happiness, pred_m2)

## MAD Metrics
MAD_m1 <- mad(testset$Happiness, pred_m1)
MAD_m2 <- mad(testset$Happiness, pred_m2)

## MAPE Metrics
MAPE_m1 <- mape(testset$Happiness, pred_m1)
MAPE_m2 <- mape(testset$Happiness, pred_m2)

## Make table with values
metrics_table <- data.frame(
  Model = c("Model 1", "Model 2"),
   RMSE = c(RMSE_m1, RMSE_m2),
   MAE = c(MAE_m1, MAE_m2),
   MAD = c(MAD_m1, MAD_m2),
   MAPE = c(MAPE_m1, MAPE_m2)
)
metrics_table
```

REC Curve and Graph

```{r}
m1_audit <- audit(model1, data = testset, y = testset$Happiness)
m2_audit <- audit(model2, data = testset, y = testset$Happiness)

mr_m1 <- model_residual(m1_audit)
mr_m2 <- model_residual(m2_audit)

plot_rec(mr_m1)
plot_rec(mr_m2)

score_rec(m1_audit)
score_rec(m2_audit)
```
Comments on REC values and Numeric Evaluation Metrics:\
Based on the Numeric Evaluation Metrics, Model 1 is the best as it leads to more predictive accuracy. Based on the REC Curve and Score, model 1 has lower prediction errors meaning model 1 predicted closer to the actual numbers. However, Model 2 will be chosen for deployment because it explains significantly more variability in the dataset then model 1 based on the adjusted R^2.\



# Deployment

## Model on entire Dataset

```{r}
set.seed(1)
model_full <- train(Happiness ~ Age + quad_age + log_income, data = happy_data, method = "lm", trControl = lm_ctrl)
summary(model_full)


```

## Predict Scenario Happiness when Income equals $80,000 and Age equals c(30, 45, 60) years.

```{r}
pred_age <- data.frame(
  Age = c(30, 45, 60),
  quad_age = c(30, 45, 60)^2,
  log_income = log(80000)
)

pred_age$predicted_happiness <- predict(model_full, newdata = pred_age)
pred_age

```

## Predict Scenario Happiness when Age = 60 and Income equals c($25,000, $75,000, $125,000)

```{r}
pred_income <- data.frame(
  Age = 60,
  quad_age = 60^2,
  log_income = log(c(25000, 75000, 125000))
)

pred_income$predicted_happiness <- predict(model_full, newdata = pred_income)
pred_income


```
## Insight to Mr. Person
In this analysis we found that both Age and Income are related to happiness. Age has a quadratic relation to happiness meaning from age 30-50.5 happiness trends downwards, but from 50.5 onwards happiness trends upwards. This can be seen when the full model is used to predict happiness based of changing ages, age 30 was the highest happiness, age 45 is the lowest level of happiness, then age 60 happiness trended upwards being higher than at age 45. Income has a positive relationship with happiness, as income increases so does happiness. This can be seen when happiness is predicted for different income amounts. $25000 had the lowest happiness, $75000 had the second highest happiness amount, and $125,000 had the highest happiness amount. If this model is deployed again the quadratic of age should be taken and log of income should also be taken as it leads to higher correlation with happiness. 


